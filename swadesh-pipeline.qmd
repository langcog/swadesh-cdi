---
title: "Swadesh CDI pipeline"
format: html
---

```{r}
library(wordbankr)
library(tidyverse)
library(glue)
library(mirt)
library(RColorBrewer)
require(gplots)
walk(list.files("scripts", pattern = "*.R$", full.names = TRUE), source)

S_LEN = 100 # Swadesh list length
N_RAND = 100 # number of random sublists to compare to
BEST_K = 23 # 
BEST_Ks = 23:29
```

# Data fetching and stitching
Get new form definitions with unified items
```{r}
languages <- list.files("data/new_items") |> str_sub(end = -5)
pronouns <- read_csv("data/pronouns.csv") |> 
  mutate(uid = glue("{form}_{itemID}"))

rep_items <- list()

# Validate to ensure no repeated items
for (language in languages) {
  ni <- get_new_items(language, pronouns)
  forms <- ni$forms
  new_items <- ni$new_items
  rep_ids <- new_items |> 
    select(category, definition) |> 
    duplicated()
  repeated <- new_items[rep_ids,]
  
  if (nrow(repeated) > 0) {
    repeated <- repeated |> 
      mutate(language = language)
    rep_items <- c(rep_items, list(repeated))
  }
}
```

Stitch data together and save outputs
```{r, eval=F}
for (language in languages) {
  ni <- get_new_items(language, pronouns)
  df <- make_data(language, ni$forms, ni$new_items)
  
  output <- list(all_demo = df$all_demo,
                 items = ni$new_items,
                 all_long = df$all_long,
                 all_prod = df$all_prod)
  
  saveRDS(output, glue("data/all_forms/{language}_data.rds"))
}
```


# IRT modelling and parameter extraction
Run 2PL models
```{r}
languages <- list.files("data/all_forms") |> str_sub(end = -10)
```

```{r eval=F}
completed <- list.files("data/prod_models") |> str_sub(end = -28)

mirtCluster()
for (language in setdiff(languages, completed)) {
  run_2PL_model(language)
}
```

Get demographics
```{r, eval=F}
demog <- lapply(languages, \(language) {
  lang_data <- readRDS(glue("data/all_forms/{language}_data.rds"))
  # FIXME: all_demo is wrong---maybe because of filter_age
  lang_data$all_long |> 
    select(language, data_id, form_type) |> 
    distinct() |> 
    count(language, form_type)
}) |> bind_rows()

included <- sapply(languages, \(language) {
  model <- readRDS(glue("data/prod_models/{language}_2PL_allforms_prod_fits.rds"))
  model$model@Data$data |> nrow()
})

demog <- demog |> 
  pivot_wider(names_from = form_type,
              values_from = n) |> 
  mutate(included = included)

saveRDS(demog, "data/intermediates/demographics.rds")
```


Collapse cross-linguistic item parameters
```{r eval=F}
xldf <- list()
full_fscores <- list()
n_subj <- c()
n_item <- c()
n_iter <- c()

for (language in languages) {
  lang_data <- readRDS(glue("data/all_forms/{language}_data.rds"))
  fitted <- readRDS(glue("data/prod_models/{language}_2PL_allforms_prod_fits.rds"))
  n_subj <- c(n_subj, nrow(fitted$model@Data$data))
  n_item <- c(n_item, ncol(fitted$model@Data$data))
  n_iter <- c(n_iter, fitted$model@OptimInfo$iter)
    
  lang_fscores <- data.frame(fscores(fitted$model, 
                                     method = "MAP",
                                     full.scores = F)) 
  full_fscores[[language]] <- tibble(full_theta = lang_fscores$G,
                                     full_sumscore = rowSums(lang_fscores |> select(-G, -SE_G), na.rm=T))
  # could also pull age from lang_data$all_demo
  df <- fitted$coefs |> 
    rename("uid" = "definition") |> 
    left_join(lang_data$items |> 
                select(uid, category, definition, gloss, uni_lemma) |> # ToDo: want lexical_category, but it's not here...
                mutate(uid = str_replace(uid, " ", ".")),
              by = "uid") |> 
    mutate(language = language)
  xldf <- c(xldf, list(df))
}
xldf <- bind_rows(xldf)
saveRDS(xldf, "data/intermediates/xldf_prod_allforms.rds")
saveRDS(full_fscores, "data/intermediates/full_fscores_allforms.rds")
# xx <- bind_rows(full_fscores)
# plot(xx$full_theta, xx$full_sumscore) # cor = .71

model_stats <- tibble(language = languages,
                      participants = n_subj,
                      items = n_item,
                      iterations = n_iter)
saveRDS(model_stats, "data/intermediates/model_stats.rds")
```

```{r, load-irt-parameters}
xldf <- readRDS("data/intermediates/xldf_prod_allforms.rds")
model_stats <- readRDS("data/intermediates/model_stats.rds")
```

Clean IRT parameters (`xldf`)
```{r}
xldf_clean <- xldf |> 
  filter(!is.na(uni_lemma), !is.na(d)) |> 
  mutate(category = case_when(
    category == "descriptive_words (adjectives)" ~ "descriptive_words",
    category == "outside_places" ~ "outside",
    category == "articles" ~ "quantifiers",
    category == "prepositions" ~ "locations",
    .default = category))

prod_pars <- xldf_clean |> 
  arrange(language, uni_lemma, desc(a1)) |> # get most discriminating uni_lemma per lang
  select(uni_lemma, language, uid, category, language, d) |>
  group_by(uni_lemma, language) |>
  slice(1) |> 
  ungroup()

gen_langs <- model_stats |> filter(participants < 300) |> pull(language)

train_langs <- setdiff(languages, gen_langs)
```

Get category proportions
```{r}
## We use canonical categories from the American English form
main_cats <- xldf_clean |> filter(language == "English (American)") |> pull(category) |> unique()
cat_props <- xldf_clean |> 
  filter(category %in% main_cats,
         language %in% train_langs) |> 
  group_by(language) |> 
  count(category) |> 
  mutate(prop = n / sum(n)) |> 
  group_by(category) |> 
  summarise(mean_prop = mean(prop))
write_csv(cat_props, "data/category_proportions.csv")
```

# Cross-validation
```{r, eval=F}
all_fscores <- readRDS("data/intermediates/full_fscores_allforms.rds")

create_cors <- function(full_model, full_fscores, lang, prod_sum, prod_test, 
                        sublist_func, sublist_name, bins = NULL, rand = FALSE) {
  if (rand) {
    lapply(2:(length(train_langs)-1), \(k) {
      sapply(1:N_RAND, \(comp) {
        sublist <- sublist_func(prod_sum, S_LEN, k)
        if (is.element(k, BEST_Ks)) { 
          fscore_cor <- tryCatch({
            get_fscore_cor(sublist, xldf_clean, lang, full_fscores)
          }, error = function(e) {
            message(glue("Error in get_fscore_cor for language {lang}, k {k}: {e$message}"))
            NA
          })
        } else {
          fscore_cor <- NA
        }
        c(get_difficulty_metrics(sublist, prod_test), fscore_cor)
      }) |> t() |> 
        `colnames<-`(c("num_overlap", "difficulty_cor", "rmse", "fscore_cor")) |> 
        as_tibble() |> 
        mutate(run = 1:N_RAND, k = k)
    }) |> bind_rows() |> 
      mutate(language = lang, sublist = sublist_name)
  } else {
    sapply(2:(length(train_langs)-1), \(k) {
      sublist <- if (is.null(bins)) sublist_func(prod_sum, S_LEN, k) else sublist_func(prod_sum, S_LEN, k, n_bins = bins)
      if (is.element(k, BEST_Ks)) { 
        fscore_cor <- tryCatch({
          get_fscore_cor(sublist, xldf_clean, lang, full_fscores)
        }, error = function(e) {
          message(glue("Error in get_fscore_cor for language {lang}, k {k}: {e$message}"))
          NA
        })
      } else {
        fscore_cor <- NA
      }
      c(get_difficulty_metrics(sublist, prod_test), fscore_cor)
    }) |> t() |> 
      `colnames<-`(c("num_overlap", "difficulty_cor", "rmse", "fscore_cor")) |> 
      as_tibble() |> 
      mutate(run = NA, k = 2:(length(train_langs)-1), language = lang, sublist = sublist_name)
  }
}

cv_res <- lapply(train_langs, \(lang) {
  message(glue("Calculating for {lang}..."))
  
  prod_cats <- prod_pars |> 
    filter(language %in% train_langs, language != lang) |> 
    group_by(uni_lemma) |> 
    count(category) |> 
    arrange(desc(category)) |> 
    slice(1)
  
  prod_sum <- prod_pars |> 
    filter(language %in% train_langs, language != lang) |> 
    group_by(uni_lemma) |> 
    summarise(num_langs = n(),
              mean_d = mean(d, na.rm = TRUE),
              sd_d = sd(d, na.rm = TRUE)) |> 
    left_join(prod_cats |> select(-n), by = join_by(uni_lemma))
  
  prod_test <- prod_pars |> filter(language == lang)
  
  # calculate full fscores once (rather than once per comparison)
  full_model <- readRDS(glue("data/prod_models/{lang}_2PL_allforms_prod_fits.rds"))
  #full_fscores <- all_fscores[[lang]]
  full_fscores <- fscores(full_model$model, 
                          response.pattern = full_model$model@Data$data, 
                          method = "MAP")[,1] 
  
  prod_cors <- create_cors(full_model, full_fscores, lang, prod_sum, prod_test, 
                           make_swadesh_sublist, "unstratified")
  bin2_cors <- create_cors(full_model, full_fscores, lang, prod_sum, prod_test, 
                           make_binned_swadesh_sublist, "2 strata", bins = 2)
  bin3_cors <- create_cors(full_model, full_fscores, lang, prod_sum, prod_test, 
                           make_binned_swadesh_sublist, "3 strata", bins = 3)
  bin4_cors <- create_cors(full_model, full_fscores, lang, prod_sum, prod_test, 
                           make_binned_swadesh_sublist, "4 strata", bins = 4)
  bin5_cors <- create_cors(full_model, full_fscores, lang, prod_sum, prod_test, 
                           make_binned_swadesh_sublist, "5 strata", bins = 5)
  cat_cors <- create_cors(full_model, full_fscores, lang, prod_sum, prod_test, 
                          make_proportional_sublist, "category")
  rand_cors <- create_cors(full_model, full_fscores, lang, prod_sum, prod_test, 
                           make_random_sublist, "Random", rand = TRUE)
  
  bind_rows(prod_cors, bin2_cors, bin3_cors, bin4_cors, bin5_cors, cat_cors, rand_cors)
}) |> bind_rows()

cv_res_sum <- cv_res |> 
  group_by(k, language, sublist) |> 
  summarise(num_overlap = mean(num_overlap),
            difficulty_cor = mean(difficulty_cor),
            fscore_cor = mean(fscore_cor),
            rmse = mean(rmse)) |> 
  mutate(difficulty_cor_t = atanh(difficulty_cor), # Fisher transform
         fscore_cor_t = atanh(fscore_cor)) 

saveRDS(cv_res_sum, "data/intermediates/full_vs_swadesh_cv_fscores_allforms.rds")
```

```{r}
cv_res_sum <- readRDS("data/intermediates/full_vs_swadesh_cv_fscores_allforms.rds")

cv_output <- cv_res_sum |> 
  group_by(k, sublist) |> 
  summarise(num_overlap = mean(num_overlap, na.rm = TRUE),
            difficulty_cor = mean(difficulty_cor, na.rm = TRUE),
            rmse = mean(rmse, na.rm=T))

cv_output |>
  ungroup() |> group_by(sublist) |>
  filter(difficulty_cor == max(difficulty_cor, na.rm = TRUE)) |>
  slice(1) |> ungroup() |> arrange(desc(difficulty_cor))
# k=26, 2 strata, num_overlap=93.2, diff_cor=.842

cv_output |>
  ungroup() |> group_by(sublist) |>
  filter(rmse == min(rmse, na.rm = TRUE)) |>
  slice(1) |> ungroup() |> arrange(rmse)
```

```{r, fig.width=10, fig.height=5}
ggplot(cv_res_sum,
       aes(x = k, y = difficulty_cor, col = sublist)) +
  geom_jitter(aes(col = sublist),
              alpha = .1) +
  geom_boxplot(aes(group = interaction(k, sublist))) +
  labs(y = "Difficulty correlation") +
  theme(legend.position = "bottom") + theme_classic()
```

```{r, fig.width=10, fig.height=5}
ggplot(cv_res_sum,
       aes(x = k, y = num_overlap, col = sublist)) +
  geom_jitter(aes(col = sublist),
              alpha = .1) +
  geom_boxplot(aes(group = interaction(k, sublist))) +
  labs(y = "Overlap") +
  theme_classic() + 
  theme(legend.position = "bottom") 
```

```{r, fig.width=9, fig.height=5}
t.test(subset(cv_res_sum, sublist=="unstratified" & k==BEST_K)$fscore_cor - 
       subset(cv_res_sum, sublist=="Random" & k==BEST_K)$fscore_cor) # n.s.
t.test(subset(cv_res_sum, sublist=="category" & k==BEST_K)$fscore_cor - 
       subset(cv_res_sum, sublist=="Random" & k==BEST_K)$fscore_cor) # n.s.
t.test(subset(cv_res_sum, sublist=="category" & k==BEST_K)$fscore_cor - 
       subset(cv_res_sum, sublist=="unstratified" & k==BEST_K)$fscore_cor) # n.s.
t.test(subset(cv_res_sum, sublist=="category" & k==BEST_K)$fscore_cor - 
       subset(cv_res_sum, sublist=="2 strata" & k==BEST_K)$fscore_cor) # n.s.
t.test(subset(cv_res_sum, sublist=="unstratified" & k==BEST_K)$fscore_cor - 
       subset(cv_res_sum, sublist=="2 strata" & k==BEST_K)$fscore_cor) # n.s.
t.test(subset(cv_res_sum, sublist=="Random" & k==BEST_K)$fscore_cor - 
       subset(cv_res_sum, sublist=="2 strata" & k==BEST_K)$fscore_cor) # n.s.

cv_res_sum %>% filter(k==BEST_K) %>%
  ggplot(aes(x = language, y = fscore_cor, group = sublist, col = sublist)) +
  geom_point(alpha=.7) + # geom_jitter
  labs(y = "Fscore correlation") +
  theme(legend.position = "bottom") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 45, hjust=0.95, vjust=0.9)) 
```


CV results show that $k=23$ is the optimal value; we use this to construct the final list for generalization testing.

# Generalization test
```{r}
all_prod <- readRDS("data/intermediates/allforms_prod_per_lang.rds")
```

```{r}
prod_cats <- prod_pars |> 
  filter(language %in% train_langs) |> 
  group_by(uni_lemma) |> 
  count(category) |> 
  arrange(desc(category)) |> 
  slice(1)
  
prod_sum <- prod_pars |> 
  filter(language %in% train_langs) |> 
  group_by(uni_lemma) |> 
  summarise(num_langs = n(),
            mean_d = mean(d, na.rm = TRUE),
            sd_d = sd(d, na.rm = TRUE)) |> 
  left_join(prod_cats |> select(-n), by = join_by(uni_lemma))

generate_sublist_cors <- function(sublist_function, bins = NULL, sublist_name) {
  sublist <- if (is.null(bins)) {
    sublist_function(prod_sum, S_LEN, BEST_K)
  } else {
    sublist_function(prod_sum, S_LEN, BEST_K, bins)
  }
  
  cors <- sapply(gen_langs, \(lang) {
    get_sumscore_cor(sublist, xldf, all_prod, lang)
  }) |> t() |>
    `colnames<-`(c("num_overlap", "sumscore_cor")) |> 
    as_tibble(rownames = "language") |> 
    mutate(sublist = sublist_name)
  
  return(cors)
}

# Unstratified (could actually use make_binned_swadesh_sublist(..., n_bins=1))
unstrat_cors <- generate_sublist_cors(make_swadesh_sublist, sublist_name = "unstratified")

# Stratified with bins 2 to 5
strat_cors_list <- lapply(2:5, function(bins) {
  generate_sublist_cors(make_binned_swadesh_sublist, bins, sublist_name = paste0(bins, " strata"))
})

# Random
rand_cors <- lapply(gen_langs, \(lang) {
  rand_cors <- sapply(1:N_RAND, \(comp) {
    sublist <- make_random_sublist(prod_sum, S_LEN, BEST_K)
    get_sumscore_cor(sublist, xldf, all_prod, lang)
  }) |> t() |> 
    `colnames<-`(c("num_overlap", "sumscore_cor")) |> 
    as_tibble() |> 
    mutate(run = 1:N_RAND,
           language = lang)
}) |> 
  bind_rows() |> 
  mutate(sublist = "Random")

# Category Proportional
category_cors <- generate_sublist_cors(make_proportional_sublist, sublist_name = "category")

# Combine all results
gen_res <- bind_rows(unstrat_cors, category_cors, rand_cors, do.call(bind_rows, strat_cors_list))

gen_res_sum <- gen_res |> 
  group_by(language, sublist) |> 
  summarise(num_overlap = mean(num_overlap),
            sumscore_cor = mean(sumscore_cor)) |> 
  mutate(sumscore_cor_t = atanh(sumscore_cor)) # Fisher transform

save(gen_res_sum, gen_res, file="data/intermediates/generalization_results.rds")
```

```{r, generate-candidate-swadesh-lists}
swadesh_sublist <- make_swadesh_sublist(prod_sum, S_LEN, BEST_K)
category_sublist <- make_proportional_sublist(prod_sum, S_LEN, BEST_K)
strat2_sublist <- make_binned_swadesh_sublist(prod_sum, S_LEN, BEST_K, n_bins=2)

# 60-66% overlap between the various methods
#intersect(category_sublist$uni_lemma, strat2_sublist$uni_lemma) # 60
#intersect(swadesh_sublist$uni_lemma, strat2_sublist$uni_lemma) # 66
#intersect(swadesh_sublist$uni_lemma, category_sublist$uni_lemma) # 66
#setdiff(swadesh_sublist$uni_lemma, category_sublist$uni_lemma)
#setdiff(category_sublist$uni_lemma, swadesh_sublist$uni_lemma)
```


```{r, fig.width=7, fig.height=4.5}
ggplot(gen_res_sum,
       aes(x = language, y = sumscore_cor, fill = sublist)) +
  geom_col(position = "dodge") +
  labs(y = "Sumscore correlation") +
  theme_classic() +
  theme(legend.position = "bottom", 
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(fill="List type")
```

```{r, fig.width=7, fig.height=4.5}
ggplot(gen_res_sum,
       aes(x = language, y = num_overlap, fill = sublist)) +
  geom_col(position = "dodge") +
  labs(y = "Overlap size") +
  theme_classic() +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
```


### Compare Swadesh thetas to full CDI thetas/sumscores (and to random sumscores)
```{r, eval=F}
full_fscores <- readRDS("data/intermediates/full_fscores_allforms.rds")

# either do this in cross-validation (show that thetas from swadesh lists are better for training languages)
# ..may not make sense for gen languages because those models are trained on little data (may not be stable parms)

# sublist vs sumscore may be similar, but backtracked thetas should be more sensitive

# swadesh_sublist$uni_lemma -> xldf$uid

# we actually want the average difficulty for Swadesh items, and we will use this to define a model to get predicted fscores from 
#swadesh_sublist$mean_d

#  https://groups.google.com/g/mirt-package/c/TLv1JFq2tCg
  
theta_comps <- tibble()
for (lang in languages) {
  lang_data <- readRDS(glue("data/all_forms/{lang}_data.rds"))
  fitted <- readRDS(glue("data/prod_models/{lang}_2PL_allforms_prod_fits.rds"))
  # get UIDs of non-Swadesh items
  swad_item_ids <- xldf %>% filter(language==lang, is.element(uni_lemma, unstrat_sublist$uni_lemma)) %>% 
    pull(uid)
  #non_swad_item_ids <- setdiff(colnames(fitted$model@Data$data), swad_item_ids)
  # mask (NA) the responses to non-Swadesh items
  masked_resps <- fitted$model@Data$data
  masked_resps[,non_swad_item_ids] = NA
  swad_resp <- masked_resps[,swad_item_ids]
  full_sumscores <- rowSums(fitted$model@Data$data, na.rm=T)
  # lang_data$all_prod # these data still have 0-producing children -- should we infer thetas for them?
  
  full_fscores_lang <- fscores(fitted$model, response.pattern=fitted$model@Data$data, method="MAP")[,1] 
  
  # this uses the trained model for this lang -- but we want to use average Swadesh item difficulties (from training langs)
  #swad_fscores <- fscores(fitted$model, response.pattern=masked_resps, method="MAP")[,1] 
  # default method is EAP; prefer MAP or ML?
  
  # this lang Swadesh uid and uni_lemmas
  lang_swad_items <- xldf_clean |> filter(language==lang, is.element(uni_lemma, swadesh_sublist$uni_lemma))
  
  # original tis lang IRT parms

  modpars_orig <- mod2values(fitted$model)
  modpars <- modpars_orig %>% filter(is.element(item, lang_swad_items$uid))
    #mutate(value = ifelse(name=='a1', 1, value)) 
  
  new_vals <- modpars %>% filter(is.element(item, lang_swad_items$uid)) %>%
    select(item, name, value) %>%
    pivot_wider(names_from=name, values_from = value) %>%
    mutate(a1 = 1) %>% #select(-d) %>% 
    left_join(lang_swad_items %>% select(uid, uni_lemma), by=c("item"="uid")) %>% # get uni_lemma
    left_join(swadesh_sublist %>% select(uni_lemma, mean_d)) %>% # get mean Swadesh difficulty
    rename(d = mean_d) %>%
    pivot_longer(cols = c(a1,d,g,u)) %>% 
    select(-uni_lemma)
  
  # https://groups.google.com/g/mirt-package/c/TLv1JFq2tCg

  new_modpars <- modpars_orig %>% 
    left_join(new_vals, by = c("item", "name")) %>% 
    mutate(value = coalesce(value.y, value.x)) |> 
    relocate(value, .after=parnum) %>%
    mutate(est = FALSE) |> 
    select(-value.x, -value.y)
  
  class(new_modpars$item) <- "character"
  
  swad_mod <- mirt(fitted$model@Data$data, 1, pars=new_modpars)
  
  swad_fscores <- fscores(swad_mod, response.pattern=masked_resps, method="MAP")[,1] 
  
  
  
  # this works, but we need to 1) remove (or NA?) non-Swadesh columns, and 2) remove (or NA?) non-Swadesh parameters
  swad_mod <- mirt(fitted$model@Data$data, 1, pars=mod2values(fitted$model))
  
  # need to only modify the parameters when making the new model -- then can use fscores on the masked response patterns
  swad_mod <- mirt(fitted$model@Data$data, 1, pars=new_modpars)
  
  # Error: Rows in supplied and starting value data.frame objects do not match. Were the
  #           data or itemtype input arguments modified?
  
  swad_mod <- mirt(masked_resps[,unique(new_vals$item)], 1, pars=mod2values(fitted$model))
  # Error: Rows in supplied and starting value data.frame objects do not match. Were the
  #           data or itemtype input arguments modified?
  # parnum has a parameter index that is related to the number of participants (rows) in the data...
  # and maybe based on alphabetical order of participant and item names??
  # modpars$parnum # 1-116; 125-128... skips around!
  # can we just renumber parnum ??
  #new_modpars2 <- new_modpars %>% mutate(parnum = 1:nrow(new_modpars)) # did not work
  
  tmp <- na.omit(data.frame(cbind(full_fscores_lang, swad_fscores, full_sumscores)))
  full_theta_vs_swad_theta = cor(tmp$full_fscores_lang, tmp$swad_fscores)
  full_sum_vs_swad_theta = cor(tmp$full_sumscores, tmp$swad_fscores)
  full_sum_vs_full_theta = cor(tmp$full_sumscores, tmp$full_fscores_lang)
  
  # random theta cors
  rand_theta_cors <- sapply(1:N_RAND, \(comp) {
      sublist <- make_random_sublist(prod_sum, S_LEN, K) # use optimal K (20)
      rand_ids <- xldf %>% filter(language==lang, is.element(uni_lemma, sublist$uni_lemma)) %>% 
        pull(uid)
      
      # sumscores for random sublist:
      rand_sumscores <- rowSums(fitted$model@Data$data[,rand_ids], na.rm=T)
      
      # fscores for random sublist:
      unselected_item_ids <- xldf %>% filter(language==lang, !is.element(uni_lemma, sublist$uni_lemma)) %>% 
        pull(uid)
      # mask (NA) the responses to non-Swadesh items
      masked_resps <- fitted$model@Data$data
      masked_resps[,unselected_item_ids] = NA
      rand_fscores <- fscores(fitted$model, response.pattern=masked_resps)[,1] # ToDo: rerun with method="MAP" (slower than EAP?)
      tmp <- na.omit(data.frame(cbind(full_fscores_lang, swad_fscores, full_sumscores, 
                                      rand_fscores, rand_sumscores)))
      list(full_theta_vs_rand_sum = cor(tmp$rand_sumscores, tmp$full_fscores_lang),
           full_theta_vs_rand_theta = cor(tmp$rand_fscores, tmp$full_fscores_lang))
  }) 
  
  
  full_theta_vs_rand_sum = mean(unlist(rand_theta_cors["full_theta_vs_rand_sum",]))
  full_theta_vs_rand_theta = mean(unlist(rand_theta_cors["full_theta_vs_rand_theta",])) 
  # ToDo: save variance?
  
  theta_comps <- bind_rows(theta_comps, tibble(
    full_theta_vs_swad_theta=full_theta_vs_swad_theta,
    full_sum_vs_swad_theta=full_sum_vs_swad_theta,
    full_sum_vs_full_theta=full_sum_vs_full_theta,
    full_theta_vs_rand_sum=full_theta_vs_rand_sum,
    full_theta_vs_rand_theta=full_theta_vs_rand_theta 
  )) # full_sum_vs_rand_theta ?
  
  theta_comps
}


saveRDS(theta_comps, "data/intermediates/full_vs_swadesh_fscores_allforms.rds")
```

(A few languages have fscore estimates fail to converge, resulting in mismatched vector lengths..need to label data rows with participant IDs and match up..)

```{r}
theta_comps <- readRDS("data/intermediates/full_vs_swadesh_fscores_allforms.rds")

theta_comps |> arrange(desc(full_sum_vs_swad_theta)) |> kableExtra::kable(digits=3) 
```

Fscore T-tests:

```{r}
t.test(atanh(theta_comps$full_theta_vs_swad_theta), atanh(theta_comps$full_theta_vs_rand_theta))

t.test(atanh(theta_comps$full_sum_vs_swad_theta), atanh(theta_comps$full_sum_vs_full_theta))
```

Not significantly different (hooray / awww).


T-tests:

Swadesh is not significantly different than random in terms of sumscore correlation:
```{r}
t.test(gen_res_sum |> filter(sublist == "unstratified") |> pull(sumscore_cor),
       gen_res_sum |> filter(sublist == "Random") |> pull(sumscore_cor),
       paired = TRUE)
```

Category proportional is also no different than random in terms of sumscore correlation:
```{r}
t.test(gen_res_sum |> filter(sublist == "category") |> pull(sumscore_cor),
       gen_res_sum |> filter(sublist == "Random") |> pull(sumscore_cor),
       paired = TRUE)
```

2 strata is also no different than random in terms of sumscore correlation:
```{r}
t.test(gen_res_sum |> filter(sublist == "2 strata") |> pull(sumscore_cor),
       gen_res_sum |> filter(sublist == "Random") |> pull(sumscore_cor),
       paired = TRUE)
```


Amount of overlap - Swadesh same as random
```{r}
t.test(gen_res_sum |> filter(sublist == "unstratified") |> pull(num_overlap),
       gen_res_sum |> filter(sublist == "Random") |> pull(num_overlap),
       paired = TRUE)
```

Proportional has less overlap than random sublists
```{r}
t.test(gen_res_sum |> filter(sublist == "category") |> pull(num_overlap),
       gen_res_sum |> filter(sublist == "Random") |> pull(num_overlap),
       paired = TRUE)
```

2 difficulty strata is not significantly different in overlap than random
```{r}
t.test(gen_res_sum |> filter(sublist == "2 strata") |> pull(num_overlap),
       gen_res_sum |> filter(sublist == "Random") |> pull(num_overlap),
       paired = TRUE)
```


Swadesh is significantly easier than all items
```{r}
t.test(swadesh_sublist$mean_d,
       prod_sum$mean_d)
```

## Examining list composition

```{r}
swad_cats <- swadesh_sublist |> mutate(sublist = "unstratified") |>
  bind_rows(category_sublist |> mutate(sublist = "category")) |>
  group_by(sublist, category) %>% summarise(n = n()) %>% arrange(desc(n)) %>%
  mutate(freq = n / sum(n))

ggplot(swad_cats, aes(x = sublist, y = n, fill = category)) +
  geom_bar(stat = "identity", position = "stack") +
  theme_minimal()
```
so many animals! also other nouns (body parts, clothing, food/drink), action words, descriptives - what about relative to distribution of frequency on other forms?
average frequency per category on a CDI:WS


```{r}
swadesh_sublist |> mutate(sublist = "unstratified") |>
  bind_rows(category_sublist |> mutate(sublist = "category")) |>
  bind_rows(strat2_sublist |> mutate(sublist = "2 strata")) |>
  bind_rows(prod_sum |> filter(num_langs>=BEST_K) |> mutate(sublist = "All (k>=23)")) |>
  ggplot(aes(x=sublist, y=mean_d)) + 
  geom_violin() + geom_jitter(alpha=.3, width=.1) + theme_classic()
```


```{r, fig.width=5, fig.height=12}

# look into NAs...kind of a lot of 'em

cat_freq <- xldf %>% # @Alvin filter to canonical categories?
  filter(#!is.na(category), 
         category!="locations_quantities_adverbs",
         category!="hold",
         category!="sounds2",
         category!="unknown") %>%
  group_by(category, language) %>%
  summarise(n = n()) %>%
  group_by(language) %>%
  mutate(freq = n / sum(n))

cat_freq %>% ggplot(aes(x=freq, y=category, group=language)) +
  geom_point(alpha=.4) +
  geom_point(data=swad_cats, aes(y=reorder(category, freq), color="red")) +
  theme_classic() + theme(legend.position="none")
```


is sd(d) predicted by variance in distributed semantic models across languages?
(animals -- and other concrete nouns -- but body partologies differ a lot cross-linguistically; and pronouns and prepositions even more)
- back uni-lemmas (or just use CDI definitions) and pick favorite multilingual LLM..(but prob can't get all languages)

- sd(d) vs. concreteness? (we know it's correlated with d..)


## Cross-linguistic similarities 

We look at the Spearman correlation between the item difficulty of each language compared to each other language. First, we look at similarities across all IRT parameters, and then we focus in on the Swadesh candidates.

```{r, echo=F, fig.width=8, fig.height=8}
get_xling_difficulty_similarity <- function(xldf) {
  languages <- unique(xldf$language)
  dif_cors <- matrix(0, nrow=length(languages), ncol=length(languages))
  dif_sims <- tibble()
  colnames(dif_cors) = languages
  rownames(dif_cors) = languages

  for(l1 in languages) {
    for(l2 in languages) {
      tmp <- xldf %>% filter(language==l1 | language==l2, !is.na(d)) %>%
        select(uni_lemma, category, category, language, d) %>% # uid, 
        group_by(uni_lemma, language) %>%
        slice(1) %>% 
        pivot_wider(names_from = language, values_from = d) %>%
        drop_na()
      dif_cors[l1,l2] <- cor(tmp[,l1], tmp[,l2], method="spearman")
      dif_sims <- bind_rows(dif_sims, tibble("Lang1" = l1, "Lang2" = l2, 
                                             "r" = cor(tmp[,l1], tmp[,l2], method="spearman")[[1]], 
                                             "N" = nrow(tmp)))
    }
  }
  return(dif_cors)
}

dif_cors <- get_xling_difficulty_similarity(xldf_clean)

Colors = brewer.pal(11,"Spectral")
diag(dif_cors) = NA
#bad_lang = c("Mandarin (Taiwanese)")
heatmap.2(dif_cors, col=Colors)
```

### Similarity in Swadesh item parameters

```{r, echo=F, fig.width=8, fig.height=8}
swad_dif_cors <- get_xling_difficulty_similarity(xldf_clean %>% 
                                              filter(is.element(uni_lemma, swadesh_sublist$uni_lemma)))

heatmap.2(swad_dif_cors, col=Colors)
```

## Baseline language similarity data

From [Bella, Batsuren, and Giunchiglia (2021)](http://ukc.disi.unitn.it/index.php/lexsim/).

```{r}
# citation:
# Gábor Bella, Khuyagbaatar Batsuren, and Fausto Giunchiglia. (2021). A Database and Visualization of the Similarity of Contemporary Lexicons. 24th International Conference on Text, Speech, and Dialogue. Olomouc, Czech Republic. Retrieved from http://ukc.disi.unitn.it/index.php/lexsim/ January 18, 2024.
lang_sims <- read.csv(file="data/similarities_1.0.tsv", sep='\t') 
# Similarity is a value between 0 and 100, confidence (Robustness) can be Low, Medium, or High. 
# The confidence of a result depends on the sizes of the lexicons over which the similarity value was computed: the smaller the lexicon sizes, the lower the confidence.

sort(unique(lang_sims$LangName_1))

# not existing: ASL, Estonian, BSL, Kiswahili, Kigiriama, 

str_split(language, " (")

matches = intersect(unique(lang_sims$LangName_1), languages) # 18
names(matches) = matches
setdiff(unique(xldf$lang_mapped), unique(lang_sims$LangName_1))


# they don't have: "American Sign Language","British Sign Language","Kiswahili" (or Swahili), "Kigiriama", Greek (Cypriot/not),
language_mapping <- c(matches, c(
  "Mandarin (Beijing)" = "Mandarin Chinese", "Mandarin (Taiwanese)" = "Mandarin Chinese",
  "Cantonese" = "Yue Chinese",
  "Norwegian" = "Norwegian Bokmål",
  #"Latvian" = "Latgalian", # is historical Latvian is close enough.. (still spoken in East Latvia..)
  "French (French)" = "French", "French (Quebecois)" = "French",
  "English (American)" = "English", "English (Australian)" = "English",
  "English (British)" = "English", "English (Irish)" = "English",
  "Portuguese (European)" = "Portuguese",
  "Spanish (Argentinian)" = "Spanish", "Spanish (Chilean)" = "Spanish",
  "Spanish (European)" = "Spanish", "Spanish (Mexican)" = "Spanish",
  "Spanish (Peruvian)" = "Spanish",
  "Greek (Cypriot)" = "Modern Greek",
  "Arabic (Saudi)" = "Standard Arabic" # or Egyptian / Moroccan ?
))
xldf <- xldf %>%
  mutate(lang_mapped = coalesce(language_mapping[language], language))

matches = intersect(unique(lang_sims$LangName_1), unique(xldf$lang_mapped)) # 26
langs_to_remove <- setdiff(unique(xldf$lang_mapped), unique(lang_sims$LangName_1))

# Replace NA values if the language doesn't have a mapping
xldf$lang_mapped[is.na(xldf$lang_mapped)] <- xldf$language[is.na(xldf$lang_mapped)]

lang_sims <- lang_sims %>%
  filter(is.element(LangName_1, language_mapping) & 
         is.element(LangName_2, language_mapping))

# table(lang_sims$Robustness) # mostly high confidence, a few medium

```

# Compare dendrogams of 

```{r}
# compare dendrograms: https://cran.r-project.org/web/packages/dendextend/vignettes/dendextend.html
require(dendextend)

lang_sims_long <- lang_sims %>% 
  bind_rows(lang_sims %>% mutate(orig_lang2 = LangName_2, 
                                 LangName_2 = LangName_1,
                                 LangName_1 = orig_lang2) %>% select(-orig_lang2)) %>%
  select(-ISO_1, -ISO_2, -Robustness)

lang_sims_mat <- lang_sims_long %>% 
  pivot_wider(values_from=Similarity, names_from = LangName_1) %>% as.data.frame()

rownames(lang_sims_mat) = lang_sims_mat$LangName_2
lang_sims_mat$LangName_2 = NULL

lang_sim_d <- dist(lang_sims_mat)
lang_sim_cl <- hclust(lang_sim_d, method = "average")
lang_sim_dend <- as.dendrogram(lang_sim_cl)

#pdf("lang_sim_dendrogram.pdf", height=100, width=10)
dendextend::plot_horiz.dendrogram(lang_sim_dend)
#dev.off()

# ToDo: do we need to use xldf_clean ?
swad_lang_sims_long <- xldf %>% 
  filter(!is.element(language, langs_to_remove)) %>%
  select(-language) %>% rename(language = lang_mapped) %>%
  filter(is.element(uni_lemma, swadesh_sublist$uni_lemma))
setdiff(unique(swad_lang_sims_long$language), names(lang_sims_mat)) # "Yue Chinese" ??
swad_dif_mat <- get_xling_difficulty_similarity(swad_lang_sims_long)

swad_d <- dist(swad_dif_mat)
swad_cl <- hclust(swad_d, method = "average")
swad_dend <- as.dendrogram(swad_cl)

dendextend::plot_horiz.dendrogram(swad_dend)


dend_diff(swad_dend, lang_sim_dend)
# more ways to distinguish differences: help(highlight_distinct_edges)
```
## Tanglegram!

- "unique" nodes are highlighted with dashed lines (i.e.: nodes which contains a combination of labels/items, which are not present in the other tree)
- connecting lines are colored to highlight two sub-trees which are present in both dendrograms (no overlap in our case..)


```{r}
dends <- dendlist(swad_dend, lang_sim_dend)

tanglegram(dends)
```

## Untangle


```{r}
dends %>% untangle(method = "step1side") %>% 
   tanglegram(common_subtrees_color_branches = TRUE)

# ToDo: some of the languages appear only in one column:
# setdiff(unique(lang_sims$LangName_2), unique(lang_sims$LangName_1))
#  "Yue Chinese"
# setdiff(unique(lang_sims$LangName_1), unique(lang_sims$LangName_2))
#  "Standard Arabic"
```

