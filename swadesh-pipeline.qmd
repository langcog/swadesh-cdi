---
title: "Swadesh CDI pipeline"
format: html
---

```{r}
library(wordbankr)
library(tidyverse)
library(glue)
library(mirt)
library(RColorBrewer)
require(gplots)
walk(list.files("scripts", pattern = "*.R$", full.names = TRUE), source)

S_LEN = 100 # Swadesh list length
N_RAND = 100 # number of random sublists to compare to
BEST_K = 25 # best for 2 strata and unstratified; k=26 for category
BEST_Ks = 23:29
```

# Data fetching and stitching
Get new form definitions with unified items
```{r}
languages <- list.files("data/new_items") |> str_sub(end = -5)
pronouns <- read_csv("data/pronouns.csv") |> 
  mutate(uid = glue("{form}_{itemID}"))

rep_items <- list()

# Validate to ensure no repeated items
for (language in languages) {
  ni <- get_new_items(language, pronouns)
  forms <- ni$forms
  new_items <- ni$new_items
  rep_ids <- new_items |> 
    select(category, definition) |> 
    duplicated()
  repeated <- new_items[rep_ids,]
  
  if (nrow(repeated) > 0) {
    repeated <- repeated |> 
      mutate(language = language)
    rep_items <- c(rep_items, list(repeated))
  }
}

# get syntactic <-> semantic category mapping
syn_cats <- read_csv("data/categories.csv",
                     col_names = c("category", "lexical_category", "lexical_class")) |> 
  distinct()
```

Stitch data together and save outputs
```{r, eval=F}
for (language in languages) {
  ni <- get_new_items(language, pronouns)
  df <- make_data(language, ni$forms, ni$new_items)
  
  output <- list(all_demo = df$all_demo,
                 items = ni$new_items,
                 all_long = df$all_long,
                 all_prod = df$all_prod)
  
  saveRDS(output, glue("data/all_forms/{language}_data.rds"))
}
```


# IRT modelling and parameter extraction
Run 2PL models
```{r}
languages <- list.files("data/all_forms") |> str_sub(end = -10)
```

```{r eval=F}
completed <- list.files("data/prod_models") |> str_sub(end = -28)

mirtCluster()
for (language in setdiff(languages, completed)) {
  run_2PL_model(language)
}
```

Get demographics
ToDo: update or remove
```{r, eval=F}
demog <- lapply(languages, \(language) {
  lang_data <- readRDS(glue("data/all_forms/{language}_data.rds"))
  # FIXME: all_demo is wrong---maybe because of filter_age
  lang_data$all_long |> 
    select(language, data_id, form_type) |> 
    distinct() |> 
    count(language, form_type)
}) |> bind_rows()

included <- sapply(languages, \(language) {
  model <- readRDS(glue("data/prod_models/{language}_2PL_allforms_prod_fits.rds"))
  model$model@Data$data |> nrow()
})

demog <- demog |> 
  pivot_wider(names_from = form_type,
              values_from = n) |> 
  mutate(included = included)

saveRDS(demog, "data/intermediates/demographics.rds")
```


Collapse cross-linguistic item parameters
```{r eval=F}
xldf <- list()
full_fscores <- list()
n_subj <- c()
n_item <- c()
n_iter <- c()

for (language in languages) {
  lang_data <- readRDS(glue("data/all_forms/{language}_data.rds"))
  fitted <- readRDS(glue("data/prod_models/{language}_2PL_allforms_prod_fits.rds"))
  n_subj <- c(n_subj, nrow(fitted$model@Data$data))
  n_item <- c(n_item, ncol(fitted$model@Data$data))
  n_iter <- c(n_iter, fitted$model@OptimInfo$iter)
    
  lang_fscores <- data.frame(fscores(fitted$model, 
                                     method = "MAP",
                                     full.scores = F)) 
  full_fscores[[language]] <- tibble(full_theta = lang_fscores$G,
                                     full_sumscore = rowSums(lang_fscores |> select(-G, -SE_G), na.rm=T))
  # could also pull age from lang_data$all_demo
  df <- fitted$coefs |> 
    rename("uid" = "definition") |> 
    left_join(lang_data$items |> 
                select(uid, category, definition, gloss, uni_lemma) |> # ToDo: want lexical_category, but it's not here...
                mutate(uid = str_replace(uid, " ", ".")),
              by = "uid") |> 
    mutate(language = language)
  xldf <- c(xldf, list(df))
}
xldf <- bind_rows(xldf)
saveRDS(xldf, "data/intermediates/xldf_prod_allforms.rds")
saveRDS(full_fscores, "data/intermediates/full_fscores_allforms.rds")
# xx <- bind_rows(full_fscores)
# plot(xx$full_theta, xx$full_sumscore) # cor = .71

model_stats <- tibble(language = languages,
                      participants = n_subj,
                      items = n_item,
                      iterations = n_iter)
saveRDS(model_stats, "data/intermediates/model_stats.rds")
```

```{r, load-irt-parameters}
xldf <- readRDS("data/intermediates/xldf_prod_allforms.rds")
model_stats <- readRDS("data/intermediates/model_stats.rds")
```

Clean IRT parameters (`xldf`)
```{r}
xldf_clean <- xldf |> 
  filter(!is.na(uni_lemma), !is.na(d)) |> 
  mutate(category = case_when(
    uni_lemma == "yes" & language == "Slovak" ~ "games_routines",
    uni_lemma == "no" & language == "Slovak" ~ "games_routines",
    uni_lemma == "peekaboo" & language == "Slovak" ~ "games_routines",
    uni_lemma == "finished" & language == "Slovak" ~ "games_routines",
    uni_lemma == "hello" & language == "Slovak" ~ "games_routines",
    uni_lemma == "bye" & language == "Slovak" ~ "games_routines",
    uni_lemma == "be" & language == "Slovak" ~ "helping_verbs",
    category == "descriptive_words (adjectives)" ~ "descriptive_words",
    category == "descriptive_words (adverbs)" ~ "descriptive_words",
    category == "outside_places" ~ "outside", 
    category == "places" ~ "outside", # combine outside and places
    category == "articles" ~ "quantifiers",
    category == "hold" ~ "household",
    category == "states" ~ "action_words",
    category == "prepositions" ~ "locations",
    category == "mental" & uni_lemma == "understand" ~ "action_words",
    category == "mental" & uni_lemma == "remember" ~ "action_words",
    category == "mental" & uni_lemma == "mad" ~ "descriptive_words",
    category == "negation_words" ~ "games_routines", # Arabic: 'finished', 'don't want', 'not mine'...
    uni_lemma == "although" & is.na(category) ~ "connecting_words",
    uni_lemma == "accident" & is.na(category) ~ "other",
    uni_lemma == "expensive" & is.na(category) ~ "descriptive_words",
    uni_lemma == "album" & category == "toys" ~ "household",
    uni_lemma == "allowed" & category == "games_routines" ~ "helping_verbs",
    uni_lemma == "bored" & is.na(category) ~ "descriptive_words",
    uni_lemma == "circle" & is.na(category) ~ "descriptive_words",
    uni_lemma == "backpack" ~ "household",
    uni_lemma == "only" ~ "quantifiers",
    uni_lemma == "material" & is.na(category) ~ "household",
    uni_lemma == "microscope" & is.na(category) ~ "toys",
    uni_lemma == "mall" ~ "outside",
    uni_lemma == "our" ~ "pronouns",
    uni_lemma == "I" ~ "pronouns",
    uni_lemma == "today" ~ "time_words",
    uni_lemma == "now" ~ "time_words",
    uni_lemma == "bounce" ~ "action_words",
    uni_lemma == "blouse" ~ "clothing",
    uni_lemma == "gas" ~ "outside",
    uni_lemma == "yet" ~ "descriptive_words",
    uni_lemma == "deep" & is.na(category) ~ "descriptive_words",
    uni_lemma == "bead" ~ "clothing",
    uni_lemma == "every" ~ "quantifiers",
    uni_lemma == "fishtank" ~ "household",
    uni_lemma == "he" ~ "pronouns",
    uni_lemma == "might" ~ "helping_verbs",
    .default = category)) |>
  mutate(uni_lemma = case_when(
    definition == "haber (hay)" ~ "have",
    definition == "musie콘" ~ "must",
    uni_lemma == "Pencil" ~ "pencil", # Catalan typo
    uni_lemma == "allowed" ~ "allow",
    uni_lemma == "mop" ~ "mop (object)",
    uni_lemma == "her" ~ "3SG.POSS", # Dutch
    uni_lemma == "he" ~ "3SG", # Mandarin (Taiwanese)
    uni_lemma == "fishtank" ~ "fish tank",
    uni_lemma == "aggrieved" ~ "upset",
    uni_lemma == "aound" ~ "round", # Irish typo
    uni_lemma == "baby chair" ~ "high chair", # 
    uni_lemma == "self" & category == "vehicles" ~ "car", # Spanish (Chilean)
    uni_lemma == "self" & category == "pronouns" ~ "1SG", # Estonian
    uni_lemma == "back" & category == "body_parts" ~ "back (body part)", 
    uni_lemma == "nail" & category == "body_parts" ~ "fingernail", 
    uni_lemma == "baker" & category == "outside" ~ "bakery", 
    uni_lemma == "bat" & category == "toys" ~ "bat (object)", 
    uni_lemma == "chicken" & category == "animals" ~ "chicken (animal)", 
    uni_lemma == "I" ~ "1SG", # Japanese (boku, watashi)
    uni_lemma == "our" ~ "1PL.POSS",
    uni_lemma == "bead" ~ "beads",
    uni_lemma == "chewing gum" ~ "gum",
    uni_lemma == "clothing" ~ "clothes",
    uni_lemma == "cock-a-doodle-doo" ~ "cockadoodledoo",
    uni_lemma == "child's name" ~ "child's own name",
    uni_lemma == "fireman" ~ "firefighter",
    uni_lemma == "fridge/freezer" ~ "fridge",
    uni_lemma == "forger" ~ "forget",
    uni_lemma == "fries" ~ "french fries",
    .default = uni_lemma
  ))

xldf_clean <- xldf_clean |>
  mutate(category = case_when(
    uni_lemma == "have" & language == "Slovak" ~ "helping_verbs",
    definition == "musie콘" ~ "helping_verbs",
    uni_lemma == "want" & language == "Slovak" ~ "helping_verbs",
    .default = category
  ))

prod_pars <- xldf_clean |> 
  arrange(language, uni_lemma, desc(a1)) |> # get most discriminating uni_lemma per lang
  select(uni_lemma, language, uid, category, language, d) |>
  group_by(uni_lemma, language) |>
  slice(1) |> 
  ungroup() |>
  left_join(syn_cats) |>
  rename(semantic_category = category,
         syntactic_category = lexical_category) |>
  select(-lexical_class)

save(prod_pars, xldf_clean, file=here("data/intermediates/xldf_clean_allforms.Rdata"))


gen_langs <- model_stats |> filter(participants < 300) |> pull(language)

train_langs <- setdiff(languages, gen_langs)
```

Get category proportions
```{r, eval=F}
# get modal semantic category per uni_lemma (xldf, or xldf_clean?)
category_counts <- xldf_clean %>%
  group_by(uni_lemma, category) %>%
  summarize(count = n(), .groups = 'drop')

modal_categories <- category_counts %>%
  group_by(uni_lemma) %>%
  filter(count == max(count)) %>%
  ungroup()

## We use canonical categories from the American English form
main_cats <- xldf_clean |> filter(language == "English (American)") |> pull(category) |> unique()
cat_props <- xldf_clean |> 
  filter(category %in% main_cats,
         language %in% train_langs) |> 
  group_by(language) |> 
  count(category) |> 
  mutate(prop = n / sum(n)) |> 
  group_by(category) |> 
  summarise(mean_prop = mean(prop))
write_csv(cat_props, "data/category_proportions.csv")

syn_cats <- read_csv("data/categories.csv",
                     col_names = c("category", "lexical_category", "lexical_class")) |> 
  distinct()
syn_props <- xldf |> 
  filter(language %in% train_langs) |> 
  left_join(syn_cats, by = join_by(category), relationship = "many-to-one") |> 
  group_by(language) |> 
  count(lexical_category) |> 
  filter(!is.na(lexical_category),
         lexical_category != "unknown") |> 
  mutate(prop = n / sum(n)) |>
  group_by(lexical_category) |> 
  summarise(mean_prop = mean(prop))
write_csv(syn_props, "data/syntactic_proportions.csv")
```

# Cross-validation

```{r}
category_props <- read_csv("data/category_proportions.csv") 
syntactic_props <- read_csv("data/syntactic_proportions.csv") |>
  rename(category = lexical_category)
```



```{r, eval=F}
all_fscores <- readRDS("data/intermediates/full_fscores_allforms.rds")


syn_cats <- read_csv("data/categories.csv",
                     col_names = c("category", "lexical_category", "lexical_class"))
# join syn_cats to xldf ? no, we actually 

create_cors <- function(full_model, full_fscores, lang, prod_sum, prod_test, 
                        sublist_func, sublist_name, bins = NULL) {
  if (sublist_name=="Random") {
    lapply(2:(length(train_langs)-1), \(k) {
      sapply(1:N_RAND, \(comp) {
        sublist <- sublist_func(prod_sum, S_LEN, k)
        if (is.element(k, BEST_Ks)) { 
          fscore_cor <- tryCatch({
            get_fscore_cor(sublist, xldf_clean, lang, full_fscores)
          }, error = function(e) {
            message(glue("Error in get_fscore_cor for language {lang}, k {k}: {e$message}"))
            NA
          })
        } else {
          fscore_cor <- NA
        }
        c(get_difficulty_metrics(sublist, prod_test), fscore_cor)
      }) |> t() |> 
        `colnames<-`(c("num_overlap", "difficulty_cor", "rmse", "fscore_cor")) |> 
        as_tibble() |> 
        mutate(run = 1:N_RAND, k = k)
    }) |> bind_rows() |> 
      mutate(language = lang, sublist = sublist_name)
  } else if(sublist_name=='syntactic' | sublist_name=='category') {
    if(sublist_name=="syntactic") { 
      cat_props = syntactic_props 
    } else {
      cat_props = category_props
    }
    sapply(2:(length(train_langs)-1), \(k) {
      sublist <- sublist_func(prod_sum, S_LEN, k, cat_props) 
      if (is.element(k, BEST_Ks)) { 
        fscore_cor <- tryCatch({
          get_fscore_cor(sublist, xldf_clean, lang, full_fscores)
        }, error = function(e) {
          message(glue("Error in get_fscore_cor for language {lang}, k {k}: {e$message}"))
          NA
        })
      } else {
        fscore_cor <- NA
      }
      c(get_difficulty_metrics(sublist, prod_test), fscore_cor) 
    }) |> t() |> 
      `colnames<-`(c("num_overlap", "difficulty_cor", "rmse", "fscore_cor")) |> 
      as_tibble() |> 
      mutate(run = NA, k = 2:(length(train_langs)-1), language = lang, sublist = sublist_name)
  } else {
    sapply(2:(length(train_langs)-1), \(k) {
      sublist <- if (is.null(bins)) sublist_func(prod_sum, S_LEN, k) else sublist_func(prod_sum, S_LEN, k, n_bins = bins)
      if (is.element(k, BEST_Ks)) { 
        fscore_cor <- tryCatch({
          get_fscore_cor(sublist, xldf_clean, lang, full_fscores)
        }, error = function(e) {
          message(glue("Error in get_fscore_cor for language {lang}, k {k}: {e$message}"))
          NA
        })
      } else {
        fscore_cor <- NA
      }
      c(get_difficulty_metrics(sublist, prod_test), fscore_cor)
    }) |> t() |> 
      `colnames<-`(c("num_overlap", "difficulty_cor", "rmse", "fscore_cor")) |> 
      as_tibble() |> 
      mutate(run = NA, k = 2:(length(train_langs)-1), language = lang, sublist = sublist_name)
  }
}

# needs to know whether to use syn_props or cat_props...
cv_res <- lapply(train_langs, \(lang) {
  message(glue("Calculating for {lang}..."))
  
  # semantic cats
  prod_semantic_cats <- prod_pars |> 
    filter(language %in% train_langs, language != lang) |> 
    group_by(uni_lemma) |> 
    count(semantic_category) |> 
    arrange(desc(semantic_category)) |> 
    slice(1)
  
  # syntactic cats
  prod_syntactic_cats <- prod_pars |> 
    filter(language %in% train_langs, language != lang) |> 
    group_by(uni_lemma) |> 
    count(syntactic_category) |> 
    arrange(desc(syntactic_category)) |> 
    slice(1)
  
  prod_semantic_sum <- prod_pars |> 
    filter(language %in% train_langs, language != lang) |> 
    group_by(uni_lemma) |> 
    summarise(num_langs = n(),
              mean_d = mean(d, na.rm = TRUE),
              sd_d = sd(d, na.rm = TRUE)) |> 
    left_join(prod_semantic_cats |> select(-n), by = join_by(uni_lemma)) |>
    rename(category=semantic_category)
  
  prod_syntactic_sum <- prod_pars |> 
    filter(language %in% train_langs, language != lang) |> 
    group_by(uni_lemma) |> 
    summarise(num_langs = n(),
              mean_d = mean(d, na.rm = TRUE),
              sd_d = sd(d, na.rm = TRUE)) |> 
    left_join(prod_syntactic_cats |> select(-n), by = join_by(uni_lemma)) |>
    rename(category=syntactic_category)
  
  prod_test <- prod_pars |> filter(language == lang)
  
  # calculate full fscores once (rather than once per comparison)
  full_model <- readRDS(glue("data/prod_models/{lang}_2PL_allforms_prod_fits.rds"))
  #full_fscores <- all_fscores[[lang]]
  full_fscores <- fscores(full_model$model, 
                          response.pattern = full_model$model@Data$data, 
                          method = "MAP")[,1] 
  
  cat_cors <- create_cors(full_model, full_fscores, lang, prod_semantic_sum, prod_test, 
                          make_proportional_sublist, "category")
  syn_cors <- create_cors(full_model, full_fscores, lang, prod_syntactic_sum, prod_test, 
                          make_proportional_sublist, "syntactic")
  prod_cors <- create_cors(full_model, full_fscores, lang, prod_semantic_sum, prod_test, 
                           make_swadesh_sublist, "unstratified")
  bin2_cors <- create_cors(full_model, full_fscores, lang, prod_semantic_sum, prod_test, 
                           make_binned_swadesh_sublist, "2 strata", bins = 2)
  bin3_cors <- create_cors(full_model, full_fscores, lang, prod_semantic_sum, prod_test, 
                           make_binned_swadesh_sublist, "3 strata", bins = 3)
  bin4_cors <- create_cors(full_model, full_fscores, lang, prod_semantic_sum, prod_test, 
                           make_binned_swadesh_sublist, "4 strata", bins = 4)
  bin5_cors <- create_cors(full_model, full_fscores, lang, prod_semantic_sum, prod_test, 
                           make_binned_swadesh_sublist, "5 strata", bins = 5)
  rand_cors <- create_cors(full_model, full_fscores, lang, prod_semantic_sum, prod_test, 
                           make_random_sublist, "Random")
  
  bind_rows(prod_cors, bin2_cors, bin3_cors, bin4_cors, bin5_cors, cat_cors, syn_cors, rand_cors)
}) |> bind_rows()

cv_res_sum <- cv_res |> 
  group_by(k, language, sublist) |> 
  summarise(num_overlap = mean(num_overlap),
            difficulty_cor = mean(difficulty_cor),
            fscore_cor = mean(fscore_cor),
            rmse = mean(rmse)) |> 
  mutate(difficulty_cor_t = atanh(difficulty_cor), # Fisher transform
         fscore_cor_t = atanh(fscore_cor)) 

saveRDS(cv_res_sum, "data/intermediates/full_vs_swadesh_cv_fscores_allforms.rds")
```

```{r}
cv_res_sum <- readRDS("data/intermediates/full_vs_swadesh_cv_fscores_allforms.rds")

cv_output <- cv_res_sum |> 
  group_by(k, sublist) |> 
  summarise(num_overlap = mean(num_overlap, na.rm = TRUE),
            difficulty_cor = mean(difficulty_cor, na.rm = TRUE),
            rmse = mean(rmse, na.rm=T))

best_k <- cv_output |>
  ungroup() |> group_by(sublist) |>
  filter(difficulty_cor == max(difficulty_cor, na.rm = TRUE)) |>
  slice(1) |> ungroup() |> arrange(desc(difficulty_cor))
best_k |> kableExtra::kable(digits=3)
# k=26, 2 strata, num_overlap=93.2, diff_cor=.842
```

10/7/24: We believe we prefer difficulty correlation over RMSE since the samples (and thus language parameters) are not directly comparable (but should be correlated)

```{r, best-by-rmse, eval=F}
# selecting by RMSE doesn't favor high overlap (and k is less consistent)
best_k <- cv_output |>
  ungroup() |> group_by(sublist) |>
  filter(rmse == min(rmse, na.rm = TRUE)) |>
  slice(1) |> ungroup() |> arrange(rmse)
best_k # |> kableExtra::kable(digits=3)
```
Best RMSE (2 strata and unstratified k=25) still have pretty high overlap (~92.3), so maybe aren't bad candidates..? But their correlations are not great (~.84, maximum is 0.855).

```{r, fig.width=8, fig.height=8, include=F}
cv_output |> filter(rmse<1.2) |>
  ggplot(aes(x=rmse, y=difficulty_cor, color=num_overlap)) + 
  facet_wrap(. ~ sublist) +
  geom_point()
```



```{r, fig.width=10, fig.height=5}
cv_res_sum |>
  #filter(is.element(sublist, c("Random","category","unstratified","2 strata"))) |> 
  ggplot(aes(x = k, y = difficulty_cor, col = sublist)) +
  geom_jitter(aes(col = sublist),
              alpha = .1) +
  geom_boxplot(aes(group = interaction(k, sublist))) +
  labs(y = "Difficulty correlation") +
  theme(legend.position = "bottom") + theme_classic()
```

ToDo: not full boxplot, just show medians ?

```{r, fig.width=10, fig.height=5}
cv_res_sum |>
    #filter(is.element(sublist, c("Random","category","unstratified","2 strata"))) |> 
ggplot(aes(x = k, y = num_overlap, col = sublist)) +
  geom_jitter(aes(col = sublist),
              alpha = .1) +
  geom_boxplot(aes(group = interaction(k, sublist))) +
  labs(y = "Overlap") +
  theme_classic() + 
  theme(legend.position = "bottom") 
```

```{r, fig.width=9, fig.height=5}
t.test(subset(cv_res_sum, sublist=="unstratified" & k==23)$fscore_cor - 
       subset(cv_res_sum, sublist=="Random" & k==23)$fscore_cor) # n.s.
t.test(subset(cv_res_sum, sublist=="category" & k==25)$fscore_cor - 
       subset(cv_res_sum, sublist=="Random" & k==23)$fscore_cor) # n.s.
t.test(subset(cv_res_sum, sublist=="category" & k==25)$fscore_cor - 
       subset(cv_res_sum, sublist=="2 strata" & k==27)$fscore_cor) # n.s.
t.test(subset(cv_res_sum, sublist=="Random" & k==23)$fscore_cor - 
       subset(cv_res_sum, sublist=="2 strata" & k==27)$fscore_cor) # n.s.
t.test(subset(cv_res_sum, sublist=="syntactic" & k==27)$fscore_cor - 
       subset(cv_res_sum, sublist=="2 strata" & k==27)$fscore_cor) # n.s.
t.test(subset(cv_res_sum, sublist=="syntactic" & k==27)$fscore_cor - 
       subset(cv_res_sum, sublist=="category" & k==25)$fscore_cor) # n.s.

t.test(subset(cv_res_sum, sublist=="category" & k==25)$fscore_cor - 
       subset(cv_res_sum, sublist=="unstratified" & k==23)$fscore_cor) # p=.001 (category better)

t.test(subset(cv_res_sum, sublist=="unstratified" & k==23)$fscore_cor - 
       subset(cv_res_sum, sublist=="2 strata" & k==27)$fscore_cor) # p<.001 (2 strata .002 better)

t.test(subset(cv_res_sum, sublist=="syntactic" & k==23)$fscore_cor - 
       subset(cv_res_sum, sublist=="2 strata" & k==27)$fscore_cor) # p=.02 (s strata better)

# identify best k for each method
cv_res_sum$best_k = F
for(i in 1:nrow(best_k)) {
  idx <- which(cv_res_sum$k==best_k[i,]$k & cv_res_sum$sublist==best_k[i,]$sublist)
  cv_res_sum[idx,]$best_k = T
}

cv_res_sum |>
  filter(best_k==T) |>
  filter(sublist!="4 strata", sublist!="5 strata") |>
  ggplot(aes(x = language, y = fscore_cor, group = sublist, col = sublist)) +
  geom_point(alpha=.7) + # geom_jitter
  labs(y = "Fscore correlation") +
  theme(legend.position = "bottom") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 45, hjust=0.95, vjust=0.9)) 
# TODO: just a table tallying for how many languages each method is the best?
```


CV results show that $k=27$ is the optimal value for the 2 difficulty strata method and the syntactic category-stratified method, $k=25$ is optimal for the semantic category-stratified method, and $k=23$ is optimal for the unstratified method.
We construct the sublist for each of these methods, and compare them in order to construct a final list for the generalization test.

# Generalization test
```{r}
all_prod <- readRDS("data/intermediates/allforms_prod_per_lang.rds")
```

```{r}

 # semantic cats
  prod_semantic_cats <- prod_pars |> 
    filter(language %in% train_langs) |> 
    group_by(uni_lemma) |> 
    count(semantic_category) |> 
    arrange(desc(semantic_category)) |> 
    slice(1)
  
  # syntactic cats
  prod_syntactic_cats <- prod_pars |> 
    filter(language %in% train_langs) |> 
    group_by(uni_lemma) |> 
    count(syntactic_category) |> 
    arrange(desc(syntactic_category)) |> 
    slice(1)
  
  prod_semantic_sum <- prod_pars |> 
    filter(language %in% train_langs) |> 
    group_by(uni_lemma) |> 
    summarise(num_langs = n(),
              mean_d = mean(d, na.rm = TRUE),
              sd_d = sd(d, na.rm = TRUE)) |> 
    left_join(prod_semantic_cats |> select(-n), by = join_by(uni_lemma)) |>
    rename(category=semantic_category)
  
  prod_syntactic_sum <- prod_pars |> 
    filter(language %in% train_langs) |> 
    group_by(uni_lemma) |> 
    summarise(num_langs = n(),
              mean_d = mean(d, na.rm = TRUE),
              sd_d = sd(d, na.rm = TRUE)) |> 
    left_join(prod_syntactic_cats |> select(-n), by = join_by(uni_lemma)) |>
    rename(category=syntactic_category)


# nrow(subset(prod_sum, num_langs>=26)) # 310 unilemmas on at least 26 forms
# nrow(subset(prod_sum, num_langs>=25)) # 342 on 25+
# nrow(subset(prod_sum, num_langs>=23)) # 392 on 23+
# random overlap: 
# length(intersect(sample(1:310, 100), sample(1:310, 100))) # ~31
# length(intersect(sample(1:392, 100), sample(1:392, 100)))


generate_sublist_cors <- function(sublist_function, sublist_name, this_k, prod_sum, bins = NULL) {
  if(sublist_name=="syntactic") {
    sublist <- sublist_function(prod_sum, S_LEN, this_k, syntactic_props)
  } else if(sublist_name=="category") {
    sublist <- sublist_function(prod_sum, S_LEN, this_k, category_props)
  } else if(is.null(bins)) {
    sublist <- sublist_function(prod_sum, S_LEN, this_k)
  } else {
    sublist <- sublist_function(prod_sum, S_LEN, this_k, bins)
  }
  
  cors <- sapply(gen_langs, \(lang) {
    get_sumscore_cor(sublist, xldf, all_prod, lang)
  }) |> t() |>
    `colnames<-`(c("num_overlap", "sumscore_cor")) |> 
    as_tibble(rownames = "language") |> 
    mutate(sublist = sublist_name)
  
  return(cors)
}

strat2_cors <- generate_sublist_cors(make_binned_swadesh_sublist, sublist_name = "2 strata", this_k = 27,
                                     prod_semantic_sum, bins = 2)

syntactic_cors <- generate_sublist_cors(make_proportional_sublist, sublist_name = "syntactic", this_k = 27,
                                        prod_syntactic_sum) 

category_cors <- generate_sublist_cors(make_proportional_sublist, sublist_name = "category", this_k = 25, 
                                       prod_semantic_sum)

unstrat_cors <- generate_sublist_cors(make_swadesh_sublist, sublist_name = "unstratified", this_k = 23,
                                      prod_semantic_sum)

# Random
rand_cors <- lapply(gen_langs, \(lang) {
  rand_cors <- sapply(1:N_RAND, \(comp) {
    sublist <- make_random_sublist(prod_sum, S_LEN, BEST_K)
    get_sumscore_cor(sublist, xldf, all_prod, lang)
  }) |> t() |> 
    `colnames<-`(c("num_overlap", "sumscore_cor")) |> 
    as_tibble() |> 
    mutate(run = 1:N_RAND,
           language = lang)
}) |> 
  bind_rows() |> 
  mutate(sublist = "Random")


# Combine all results
gen_res <- bind_rows(unstrat_cors, syntactic_cors, category_cors, rand_cors, strat2_cors)

gen_res_sum <- gen_res |> 
  group_by(language, sublist) |> 
  summarise(num_overlap = mean(num_overlap),
            sumscore_cor = mean(sumscore_cor)) |> 
  mutate(sumscore_cor_t = atanh(sumscore_cor)) # Fisher transform

save(gen_res_sum, gen_res, file="data/intermediates/generalization_results.rds")
```

```{r, generate-candidate-swadesh-lists}
unstrat_sublist <- make_swadesh_sublist(prod_semantic_sum, S_LEN, 23)
category_sublist <- make_proportional_sublist(prod_semantic_sum, S_LEN, 25, category_props) 
syntactic_sublist <- make_proportional_sublist(prod_syntactic_sum, S_LEN, 27, syntactic_props) 
strat2_sublist <- make_binned_swadesh_sublist(prod_semantic_sum, S_LEN, 27, n_bins=2)

save(unstrat_sublist, category_sublist, syntactic_sublist, strat2_sublist,
     file="data/intermediates/best_k_swadesh_lists.rds")

table(unstrat_sublist$category) # 16 categories - few action words, more animals
table(category_sublist$category) # 21 cats - more actions, 
table(strat2_sublist$category) # 16 cats
table(syntactic_sublist$category) # ToDo: merge semantic category in..
# function_words          nouns          other     predicates 
#            13             46             16             25 

setdiff(unique(category_sublist$category), unique(unstrat_sublist$category))
# "quantifiers" "pronouns" "connecting_words" "helping_verbs" "furniture_rooms" 


# 62-96% overlap between the various methods
intersect(strat2_sublist$uni_lemma, category_sublist$uni_lemma) # 62
intersect(unstrat_sublist$uni_lemma, category_sublist$uni_lemma) # 62
intersect(unstrat_sublist$uni_lemma, strat2_sublist$uni_lemma) # 85
intersect(unstrat_sublist$uni_lemma, syntactic_sublist$uni_lemma) # 80
intersect(category_sublist$uni_lemma, syntactic_sublist$uni_lemma) # 65

intersect(category_sublist$uni_lemma, intersect(unstrat_sublist$uni_lemma, strat2_sublist$uni_lemma)) # 58

setdiff(unstrat_sublist$uni_lemma, category_sublist$uni_lemma) # a lot of extra sounds and animals
setdiff(category_sublist$uni_lemma, unstrat_sublist$uni_lemma)

setdiff(category_sublist$uni_lemma, strat2_sublist$uni_lemma)
setdiff(strat2_sublist$uni_lemma, category_sublist$uni_lemma)
```


```{r, fig.width=7, fig.height=4.5}
ggplot(gen_res_sum,
       aes(x = language, y = sumscore_cor, fill = sublist)) +
  geom_col(position = "dodge") + 
  labs(y = "Sumscore correlation") +
  theme_classic() +
  theme(legend.position = "bottom", 
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(fill="List type")
```

```{r, fig.width=7, fig.height=4.5}
ggplot(gen_res_sum,
       aes(x = language, y = num_overlap, fill = sublist)) +
  geom_col(position = "dodge") +
  labs(y = "Overlap size") +
  theme_classic() +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
```


### Compare Swadesh thetas to full CDI thetas/sumscores (and to random sumscores)
```{r, eval=F}
full_fscores <- readRDS("data/intermediates/full_fscores_allforms.rds")
# either do this in cross-validation (show that thetas from swadesh lists are better for training languages)
# ..may not make sense for gen languages because those models are trained on little data (may not be stable parms)

# sublist vs sumscore may be similar, but backtracked thetas should be more sensitive

# swadesh_sublist$uni_lemma -> xldf$uid

# we actually want the average difficulty for Swadesh items, and we will use this to define a model to get predicted fscores from 
#swadesh_sublist$mean_d

#  https://groups.google.com/g/mirt-package/c/TLv1JFq2tCg
  
theta_comps <- tibble()
for (lang in languages) {
  lang_data <- readRDS(glue("data/all_forms/{lang}_data.rds"))
  fitted <- readRDS(glue("data/prod_models/{lang}_2PL_allforms_prod_fits.rds"))
  # get UIDs of non-Swadesh items
  swad_item_ids <- xldf %>% filter(language==lang, is.element(uni_lemma, unstrat_sublist$uni_lemma)) %>% 
    pull(uid)
  #non_swad_item_ids <- setdiff(colnames(fitted$model@Data$data), swad_item_ids)
  # mask (NA) the responses to non-Swadesh items
  masked_resps <- fitted$model@Data$data
  masked_resps[,non_swad_item_ids] = NA
  swad_resp <- masked_resps[,swad_item_ids]
  full_sumscores <- rowSums(fitted$model@Data$data, na.rm=T)
  # lang_data$all_prod # these data still have 0-producing children -- should we infer thetas for them?
  
  full_fscores_lang <- fscores(fitted$model, response.pattern=fitted$model@Data$data, method="MAP")[,1] 
  
  # this uses the trained model for this lang -- but we want to use average Swadesh item difficulties (from training langs)
  #swad_fscores <- fscores(fitted$model, response.pattern=masked_resps, method="MAP")[,1] 
  # default method is EAP; prefer MAP or ML?
  
  # this lang Swadesh uid and uni_lemmas
  lang_swad_items <- xldf_clean |> filter(language==lang, is.element(uni_lemma, swadesh_sublist$uni_lemma))
  
  # original tis lang IRT parms

  modpars_orig <- mod2values(fitted$model)
  modpars <- modpars_orig %>% filter(is.element(item, lang_swad_items$uid))
    #mutate(value = ifelse(name=='a1', 1, value)) 
  
  new_vals <- modpars %>% filter(is.element(item, lang_swad_items$uid)) %>%
    select(item, name, value) %>%
    pivot_wider(names_from=name, values_from = value) %>%
    mutate(a1 = 1) %>% #select(-d) %>% 
    left_join(lang_swad_items %>% select(uid, uni_lemma), by=c("item"="uid")) %>% # get uni_lemma
    left_join(swadesh_sublist %>% select(uni_lemma, mean_d)) %>% # get mean Swadesh difficulty
    rename(d = mean_d) %>%
    pivot_longer(cols = c(a1,d,g,u)) %>% 
    select(-uni_lemma)
  
  # https://groups.google.com/g/mirt-package/c/TLv1JFq2tCg

  new_modpars <- modpars_orig %>% 
    left_join(new_vals, by = c("item", "name")) %>% 
    mutate(value = coalesce(value.y, value.x)) |> 
    relocate(value, .after=parnum) %>%
    mutate(est = FALSE) |> 
    select(-value.x, -value.y)
  
  class(new_modpars$item) <- "character"
  
  swad_mod <- mirt(fitted$model@Data$data, 1, pars=new_modpars)
  
  swad_fscores <- fscores(swad_mod, response.pattern=masked_resps, method="MAP")[,1] 
  
  
  
  # this works, but we need to 1) remove (or NA?) non-Swadesh columns, and 2) remove (or NA?) non-Swadesh parameters
  swad_mod <- mirt(fitted$model@Data$data, 1, pars=mod2values(fitted$model))
  
  # need to only modify the parameters when making the new model -- then can use fscores on the masked response patterns
  swad_mod <- mirt(fitted$model@Data$data, 1, pars=new_modpars)
  
  # Error: Rows in supplied and starting value data.frame objects do not match. Were the
  #           data or itemtype input arguments modified?
  
  swad_mod <- mirt(masked_resps[,unique(new_vals$item)], 1, pars=mod2values(fitted$model))
  # Error: Rows in supplied and starting value data.frame objects do not match. Were the
  #           data or itemtype input arguments modified?
  # parnum has a parameter index that is related to the number of participants (rows) in the data...
  # and maybe based on alphabetical order of participant and item names??
  # modpars$parnum # 1-116; 125-128... skips around!
  # can we just renumber parnum ??
  #new_modpars2 <- new_modpars %>% mutate(parnum = 1:nrow(new_modpars)) # did not work
  
  tmp <- na.omit(data.frame(cbind(full_fscores_lang, swad_fscores, full_sumscores)))
  full_theta_vs_swad_theta = cor(tmp$full_fscores_lang, tmp$swad_fscores)
  full_sum_vs_swad_theta = cor(tmp$full_sumscores, tmp$swad_fscores)
  full_sum_vs_full_theta = cor(tmp$full_sumscores, tmp$full_fscores_lang)
  
  # random theta cors
  rand_theta_cors <- sapply(1:N_RAND, \(comp) {
      sublist <- make_random_sublist(prod_sum, S_LEN, K) # use optimal K (20)
      rand_ids <- xldf %>% filter(language==lang, is.element(uni_lemma, sublist$uni_lemma)) %>% 
        pull(uid)
      
      # sumscores for random sublist:
      rand_sumscores <- rowSums(fitted$model@Data$data[,rand_ids], na.rm=T)
      
      # fscores for random sublist:
      unselected_item_ids <- xldf %>% filter(language==lang, !is.element(uni_lemma, sublist$uni_lemma)) %>% 
        pull(uid)
      # mask (NA) the responses to non-Swadesh items
      masked_resps <- fitted$model@Data$data
      masked_resps[,unselected_item_ids] = NA
      rand_fscores <- fscores(fitted$model, response.pattern=masked_resps)[,1] # ToDo: rerun with method="MAP" (slower than EAP?)
      tmp <- na.omit(data.frame(cbind(full_fscores_lang, swad_fscores, full_sumscores, 
                                      rand_fscores, rand_sumscores)))
      list(full_theta_vs_rand_sum = cor(tmp$rand_sumscores, tmp$full_fscores_lang),
           full_theta_vs_rand_theta = cor(tmp$rand_fscores, tmp$full_fscores_lang))
  }) 
  
  
  full_theta_vs_rand_sum = mean(unlist(rand_theta_cors["full_theta_vs_rand_sum",]))
  full_theta_vs_rand_theta = mean(unlist(rand_theta_cors["full_theta_vs_rand_theta",])) 
  # ToDo: save variance?
  
  theta_comps <- bind_rows(theta_comps, tibble(
    full_theta_vs_swad_theta=full_theta_vs_swad_theta,
    full_sum_vs_swad_theta=full_sum_vs_swad_theta,
    full_sum_vs_full_theta=full_sum_vs_full_theta,
    full_theta_vs_rand_sum=full_theta_vs_rand_sum,
    full_theta_vs_rand_theta=full_theta_vs_rand_theta 
  )) # full_sum_vs_rand_theta ?
  
  theta_comps
}


saveRDS(theta_comps, "data/intermediates/full_vs_swadesh_fscores_allforms.rds")
```

(A few languages have fscore estimates fail to converge, resulting in mismatched vector lengths..need to label data rows with participant IDs and match up..)

```{r}
theta_comps <- readRDS("data/intermediates/full_vs_swadesh_fscores_allforms.rds")

theta_comps |> arrange(desc(full_sum_vs_swad_theta)) |> kableExtra::kable(digits=3) 
```

Fscore T-tests:

```{r}
t.test(atanh(theta_comps$full_theta_vs_swad_theta), atanh(theta_comps$full_theta_vs_rand_theta))

t.test(atanh(theta_comps$full_sum_vs_swad_theta), atanh(theta_comps$full_sum_vs_full_theta))
```

Not significantly different (hooray / awww).


T-tests:

The Swadesh sublist selection methods are not significantly different than random in terms of sumscore correlation:
```{r}
t.test(gen_res_sum |> filter(sublist == "unstratified") |> pull(sumscore_cor),
       gen_res_sum |> filter(sublist == "Random") |> pull(sumscore_cor),
       paired = TRUE)

t.test(gen_res_sum |> filter(sublist == "2 strata") |> pull(sumscore_cor),
       gen_res_sum |> filter(sublist == "Random") |> pull(sumscore_cor),
       paired = TRUE)

t.test(gen_res_sum |> filter(sublist == "category") |> pull(sumscore_cor),
       gen_res_sum |> filter(sublist == "Random") |> pull(sumscore_cor),
       paired = TRUE)
```


Amount of overlap - unstratified no different than random
```{r}
t.test(gen_res_sum |> filter(sublist == "unstratified") |> pull(num_overlap),
       gen_res_sum |> filter(sublist == "Random") |> pull(num_overlap),
       paired = TRUE)
```

Category stratified has less overlap than random sublists
```{r}
t.test(gen_res_sum |> filter(sublist == "category") |> pull(num_overlap),
       gen_res_sum |> filter(sublist == "Random") |> pull(num_overlap),
       paired = TRUE)
```

2 difficulty strata is not significantly different in overlap than random
```{r}
t.test(gen_res_sum |> filter(sublist == "2 strata") |> pull(num_overlap),
       gen_res_sum |> filter(sublist == "Random") |> pull(num_overlap),
       paired = TRUE)
```


All of the methods result in sublists that are significantly easier than all items
```{r}
t.test(unstrat_sublist$mean_d,
       prod_sum$mean_d)
```


```{r}
t.test(strat2_sublist$mean_d,
       prod_sum$mean_d)
```

```{r}
t.test(category_sublist$mean_d,
       prod_sum$mean_d)
```

## Examining list composition

```{r}
swad_cats <- unstrat_sublist |> mutate(sublist = "unstratified") |>
  bind_rows(category_sublist |> mutate(sublist = "category")) |>
  bind_rows(strat2_sublist |> mutate(sublist = "2 strat")) |>
  group_by(sublist, category) %>% summarise(n = n()) %>% arrange(desc(n)) %>%
  mutate(freq = n / sum(n))

ggplot(swad_cats, aes(x = sublist, y = n, fill = category)) +
  geom_bar(stat = "identity", position = "stack") +
  theme_minimal()
```
so many animals! also other nouns (body parts, clothing, food/drink), action words, descriptives - what about relative to distribution of frequency on other forms?
average frequency per category on a CDI:WS


```{r}
unstrat_sublist |> mutate(sublist = "unstratified") |>
  bind_rows(category_sublist |> mutate(sublist = "category")) |>
  bind_rows(strat2_sublist |> mutate(sublist = "2 strata")) |>
  bind_rows(prod_sum |> filter(num_langs>=BEST_K) |> mutate(sublist = "All (k>=23)")) |>
  ggplot(aes(x=sublist, y=mean_d)) + 
  geom_violin() + geom_jitter(alpha=.3, width=.1) + theme_classic()
```


```{r, fig.width=5, fig.height=12}

# look into NAs...kind of a lot of 'em

cat_freq <- xldf %>% # @Alvin filter to canonical categories?
  filter(#!is.na(category), 
         category!="locations_quantities_adverbs",
         category!="sounds2",
         category!="unknown") %>%
  group_by(category, language) %>%
  summarise(n = n()) %>%
  group_by(language) %>%
  mutate(freq = n / sum(n))

cat_freq %>% ggplot(aes(x=freq, y=category, group=language)) +
  geom_point(alpha=.4) +
  geom_point(data=swad_cats, aes(y=reorder(category, freq), color="red")) +
  theme_classic() + theme(legend.position="none")
```


is sd(d) predicted by variance in distributed semantic models across languages?
(animals -- and other concrete nouns -- but body partologies differ a lot cross-linguistically; and pronouns and prepositions even more)
- back uni-lemmas (or just use CDI definitions) and pick favorite multilingual LLM..(but prob can't get all languages)

- sd(d) vs. concreteness? (we know it's correlated with d..)


## Cross-linguistic similarities 

We look at the Spearman correlation between the item difficulty of each language compared to each other language. First, we look at similarities across all IRT parameters, and then we focus in on the Swadesh candidates.

```{r, echo=F, fig.width=8, fig.height=8}
get_xling_difficulty_similarity <- function(xldf) {
  languages <- unique(xldf$language)
  dif_cors <- matrix(0, nrow=length(languages), ncol=length(languages))
  dif_sims <- tibble()
  colnames(dif_cors) = languages
  rownames(dif_cors) = languages

  for(l1 in languages) {
    for(l2 in languages) {
      tmp <- xldf %>% filter(language==l1 | language==l2, !is.na(d)) %>%
        select(uni_lemma, category, category, language, d) %>% # uid, 
        group_by(uni_lemma, language) %>%
        slice(1) %>% 
        pivot_wider(names_from = language, values_from = d) %>%
        drop_na()
      dif_cors[l1,l2] <- cor(tmp[,l1], tmp[,l2], method="spearman")
      dif_sims <- bind_rows(dif_sims, tibble("Lang1" = l1, "Lang2" = l2, 
                                             "r" = cor(tmp[,l1], tmp[,l2], method="spearman")[[1]], 
                                             "N" = nrow(tmp)))
    }
  }
  return(dif_cors)
}

dif_cors <- get_xling_difficulty_similarity(xldf_clean)

Colors = brewer.pal(11,"Spectral")
diag(dif_cors) = NA
#bad_lang = c("Mandarin (Taiwanese)")
heatmap.2(dif_cors, col=Colors)
```

### Similarity in Swadesh item parameters

```{r, echo=F, fig.width=8, fig.height=8}
swad_dif_cors <- get_xling_difficulty_similarity(xldf_clean %>% 
                                              filter(is.element(uni_lemma, swadesh_sublist$uni_lemma)))

heatmap.2(swad_dif_cors, col=Colors)
```

## Baseline language similarity data

From [Bella, Batsuren, and Giunchiglia (2021)](http://ukc.disi.unitn.it/index.php/lexsim/).

```{r}
# citation:
# G치bor Bella, Khuyagbaatar Batsuren, and Fausto Giunchiglia. (2021). A Database and Visualization of the Similarity of Contemporary Lexicons. 24th International Conference on Text, Speech, and Dialogue. Olomouc, Czech Republic. Retrieved from http://ukc.disi.unitn.it/index.php/lexsim/ January 18, 2024.
lang_sims <- read.csv(file="data/similarities_1.0.tsv", sep='\t') 
# Similarity is a value between 0 and 100, confidence (Robustness) can be Low, Medium, or High. 
# The confidence of a result depends on the sizes of the lexicons over which the similarity value was computed: the smaller the lexicon sizes, the lower the confidence.

sort(unique(lang_sims$LangName_1))

# not existing: ASL, Estonian, BSL, Kiswahili, Kigiriama, 

str_split(language, " (")

matches = intersect(unique(lang_sims$LangName_1), languages) # 18
names(matches) = matches
setdiff(unique(xldf$lang_mapped), unique(lang_sims$LangName_1))


# they don't have: "American Sign Language","British Sign Language","Kiswahili" (or Swahili), "Kigiriama", Greek (Cypriot/not),
language_mapping <- c(matches, c(
  "Mandarin (Beijing)" = "Mandarin Chinese", "Mandarin (Taiwanese)" = "Mandarin Chinese",
  "Cantonese" = "Yue Chinese",
  "Norwegian" = "Norwegian Bokm친l",
  #"Latvian" = "Latgalian", # is historical Latvian is close enough.. (still spoken in East Latvia..)
  "French (French)" = "French", "French (Quebecois)" = "French",
  "English (American)" = "English", "English (Australian)" = "English",
  "English (British)" = "English", "English (Irish)" = "English",
  "Portuguese (European)" = "Portuguese",
  "Spanish (Argentinian)" = "Spanish", "Spanish (Chilean)" = "Spanish",
  "Spanish (European)" = "Spanish", "Spanish (Mexican)" = "Spanish",
  "Spanish (Peruvian)" = "Spanish",
  "Greek (Cypriot)" = "Modern Greek",
  "Arabic (Saudi)" = "Standard Arabic" # or Egyptian / Moroccan ?
))
xldf <- xldf %>%
  mutate(lang_mapped = coalesce(language_mapping[language], language))

matches = intersect(unique(lang_sims$LangName_1), unique(xldf$lang_mapped)) # 26
langs_to_remove <- setdiff(unique(xldf$lang_mapped), unique(lang_sims$LangName_1))

# Replace NA values if the language doesn't have a mapping
xldf$lang_mapped[is.na(xldf$lang_mapped)] <- xldf$language[is.na(xldf$lang_mapped)]

lang_sims <- lang_sims %>%
  filter(is.element(LangName_1, language_mapping) & 
         is.element(LangName_2, language_mapping))

# table(lang_sims$Robustness) # mostly high confidence, a few medium

```

# Compare dendrogams of 

```{r}
# compare dendrograms: https://cran.r-project.org/web/packages/dendextend/vignettes/dendextend.html
require(dendextend)

lang_sims_long <- lang_sims %>% 
  bind_rows(lang_sims %>% mutate(orig_lang2 = LangName_2, 
                                 LangName_2 = LangName_1,
                                 LangName_1 = orig_lang2) %>% select(-orig_lang2)) %>%
  select(-ISO_1, -ISO_2, -Robustness)

lang_sims_mat <- lang_sims_long %>% 
  pivot_wider(values_from=Similarity, names_from = LangName_1) %>% as.data.frame()

rownames(lang_sims_mat) = lang_sims_mat$LangName_2
lang_sims_mat$LangName_2 = NULL

lang_sim_d <- dist(lang_sims_mat)
lang_sim_cl <- hclust(lang_sim_d, method = "average")
lang_sim_dend <- as.dendrogram(lang_sim_cl)

#pdf("lang_sim_dendrogram.pdf", height=100, width=10)
dendextend::plot_horiz.dendrogram(lang_sim_dend)
#dev.off()

# ToDo: do we need to use xldf_clean ?
swad_lang_sims_long <- xldf %>% 
  filter(!is.element(language, langs_to_remove)) %>%
  select(-language) %>% rename(language = lang_mapped) %>%
  filter(is.element(uni_lemma, swadesh_sublist$uni_lemma))
setdiff(unique(swad_lang_sims_long$language), names(lang_sims_mat)) # "Yue Chinese" ??
swad_dif_mat <- get_xling_difficulty_similarity(swad_lang_sims_long)

swad_d <- dist(swad_dif_mat)
swad_cl <- hclust(swad_d, method = "average")
swad_dend <- as.dendrogram(swad_cl)

dendextend::plot_horiz.dendrogram(swad_dend)


dend_diff(swad_dend, lang_sim_dend)
# more ways to distinguish differences: help(highlight_distinct_edges)
```
## Tanglegram!

- "unique" nodes are highlighted with dashed lines (i.e.: nodes which contains a combination of labels/items, which are not present in the other tree)
- connecting lines are colored to highlight two sub-trees which are present in both dendrograms (no overlap in our case..)


```{r}
dends <- dendlist(swad_dend, lang_sim_dend)

tanglegram(dends)
```

## Untangle


```{r}
dends %>% untangle(method = "step1side") %>% 
   tanglegram(common_subtrees_color_branches = TRUE)

# ToDo: some of the languages appear only in one column:
# setdiff(unique(lang_sims$LangName_2), unique(lang_sims$LangName_1))
#  "Yue Chinese"
# setdiff(unique(lang_sims$LangName_1), unique(lang_sims$LangName_2))
#  "Standard Arabic"
```

